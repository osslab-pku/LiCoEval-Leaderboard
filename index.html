<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>LiCoEval Leaderboard</title>
    <link rel="stylesheet" href="style.css">
    <link rel="icon" href="./icons/osslab.png" type="image/x-icon">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/Chart.js/4.4.1/chart.umd.js"></script>
</head>
<body>
<div class="title-introduction">
    <h1>LiCoEval Leaderboard</h1>
    <p>A benchmark to evaluate the ability of LLMs to provide accurate license information for their generated
        code</p>
    <section class="benchmark-link">
        <div class="benchmark-link-item">
            <a href="https://github.com/osslab-pku/LiCoEval">
                <img src="icons/github.svg" alt="GitHub">
            </a>
        </div>
        <div class="benchmark-link-item">
            <a href="https://github.com/osslab-pku/LiCoEval">
                <img src="icons/huggingface.svg" alt="Hugging Face">
            </a>
        </div>
        <div class="benchmark-link-item">
            <a href="https://arxiv.org/abs/2408.02487">
                <img src="icons/arxiv.svg" alt="ArXiv">
            </a>
        </div>
    </section>
</div>

<div class="button-container">
    <button class="tab-button active" data-tab="LiCoEval">LiCoEval</button>
    <button class="tab-button" data-tab="HumanEval">HumanEval</button>
</div>

<div class="content-container">
    <div class="tab-content active" id="LiCoEval">
        <div class="graph">
            <canvas id="LiCoChart"></canvas>
        </div>

        <div class="leaderboard-table">
            <table>
                <thead class="first-line">
                <tr>
                    <th></th>
                    <th>Models</th>
                    <th>LiCoEval Scores</th>
                </tr>
                </thead>
                <tbody>
                <tr class="general">
                    <td rowspan="8" style="font-weight: bold;">General LLM</td>
                    <td>GPT-3.5-Turbo</td>
                    <td>0.373</td>
                </tr>
                <tr class="general">
                    <td>GPT-4-Turbo</td>
                    <td>0.376</td>
                </tr>
                <tr class="general">
                    <td>GPT4o</td>
                    <td>0.385</td>
                </tr>
                <tr class="general">
                    <td>Gemini-1.5-Pro</td>
                    <td>0.317</td>
                </tr>
                <tr class="general">
                    <td>Claude-3.5-Sonnet</td>
                    <td>0.571</td>
                </tr>
                <tr class="general">
                    <td>Qwen2-7B-Instruct</td>
                    <td>0.985</td>
                </tr>
                <tr class="general">
                    <td>GLM-4-9B-Chat</td>
                    <td>1.0</td>
                </tr>
                <tr class="general">
                    <td>Llama-3-8B-Instruct</td>
                    <td>0.714</td>
                </tr>
                <tr class="code">
                    <td rowspan="6" style="font-weight: bold;">Code LLM</td>
                    <td>DeepSeek-Coder-V2</td>
                    <td>0.142</td>
                </tr>
                <tr class="code">
                    <td>CodeQwen1.5-7B-Chat</td>
                    <td>0.781</td>
                </tr>
                <tr class="code">
                    <td>StarCoder2-15B-Instruct</td>
                    <td>0.780</td>
                </tr>
                <tr class="code">
                    <td>Codestral-22B-v0.1</td>
                    <td>0.360</td>
                </tr>
                <tr class="code">
                    <td>CodeGemma-7B-IT</td>
                    <td>0.809</td>
                </tr>
                <tr class="code">
                    <td>WizardCoder-Python-13B</td>
                    <td>0.153</td>
                </tr>
                </tbody>
            </table>
        </div>
    </div>

    <div class="tab-content" id="HumanEval">
        <div class="graph">
            <canvas id="HumanChart"></canvas>
        </div>

        <div class="leaderboard-table">
            <table>
                <thead>
                <tr class="first-line">
                    <th></th>
                    <th>Models</th>
                    <th>HumanEval Scores</th>
                </tr>
                </thead>
                <tbody>
                <tr class="general">
                    <td rowspan="8" style="font-weight: bold;">General LLM</td>
                    <td>GPT-3.5-Turbo</td>
                    <td>72.6</td>
                </tr>
                <tr class="general">
                    <td>GPT-4-Turbo</td>
                    <td>85.4</td>
                </tr>
                <tr class="general">
                    <td>GPT4o</td>
                    <td>90.2</td>
                </tr>
                <tr class="general">
                    <td>Gemini-1.5-Pro</td>
                    <td>71.9</td>
                </tr>
                <tr class="general">
                    <td>Claude-3.5-Sonnet</td>
                    <td>92.0</td>
                </tr>
                <tr class="general">
                    <td>Qwen2-7B-Instruct</td>
                    <td>79.9</td>
                </tr>
                <tr class="general">
                    <td>GLM-4-9B-Chat</td>
                    <td>71.8</td>
                </tr>
                <tr class="general">
                    <td>Llama-3-8B-Instruct</td>
                    <td>62.2</td>
                </tr>
                <tr class="code">
                    <td rowspan="6" style="font-weight: bold;">Code LLM</td>
                    <td>DeepSeek-Coder-V2</td>
                    <td>90.2</td>
                </tr>
                <tr class="code">
                    <td>CodeQwen1.5-7B-Chat</td>
                    <td>83.5</td>
                </tr>
                <tr class="code">
                    <td>StarCoder2-15B-Instruct</td>
                    <td>72.6</td>
                </tr>
                <tr class="code">
                    <td>Codestral-22B-v0.1</td>
                    <td>61.5</td>
                </tr>
                <tr class="code">
                    <td>CodeGemma-7B-IT</td>
                    <td>56.1</td>
                </tr>
                <tr class="code">
                    <td>WizardCoder-Python-13B</td>
                    <td>64.0</td>
                </tr>
                </tbody>
            </table>
        </div>
    </div>
</div>

<div class="notes">
    <h2>Notes</h2>
    <ol>
        <li>We design a framework for evaluating the license compliance capabilities of LLMs in code generation and
            provide the first benchmark for evaluating this capability. In addition, we evaluate the license
            compliance capabilities of 14 popular LLMs, providing insight into improving the LLM training process
            and regulating LLM usage.</li>
        <li>The data above comes from <a href="https://arxiv.org/pdf/2408.02487">the paper</a>.</li>
        <li>Want to use this benchmark? Please visit <a href="https://github.com/osslab-pku/LiCoEval">GitHub
            repository</a> for more!</li>
    </ol>
</div>

<div class="recommendation">
    <h2>Recommendations</h2>
    <p>It is recommended to comprehensively understand LLM coding ability through a diverse set of benchmarks and
        leaderboards, such as:</p>
    <table>
        <tbody>
        <tr>
            <td>
                <p><a href="https://fudanselab-classeval.github.io/leaderboard.html">ClassEval Leaderboard</a></p>
            </td>
        </tr>
        <tr>
            <td>
                <p><a href="https://crux-eval.github.io/leaderboard.html">CRUXEval Leaderboard</a></p>
            </td>
        </tr>
        <tr>
            <td>
                <p><a href="https://evalplus.github.io/leaderboard.html">EvalPlus Leaderboard</a></p>
            </td>
        </tr>
        <tr>
            <td>
                <p><a href="https://huggingface.co/spaces/lmarena-ai/chatbot-arena-leaderboard">Chatbot Arena Leaderboard</a></p>
            </td>
        </tr>
        <tr>
            <td>
                <p><a href="https://leaderboard.tabbyml.com/">TabbyML Leaderboard</a></p>
            </td>
        </tr>
        </tbody>
    </table>
    <p>OSSlab-PKU ❤️ Open Source</p>
    <p>OSSlab-PKU ❤️ LLMs</p>
</div>

<script src="script.js"></script>
</body>
</html>