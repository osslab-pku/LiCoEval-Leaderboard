<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>LiCoEval Leaderboard</title>
    <link rel="stylesheet" href="style.css">
    <link rel="icon" href="./icons/osslab.png" type="image/x-icon">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/Chart.js/4.4.1/chart.umd.js"></script>
</head>
<body>
<main>
    <div class="title-introduction">
        <h1>LiCoEval Leaderboard</h1>
        <p>A benchmark to evaluate the ability of LLMs to provide accurate license information for their generated
            code.</p>
        <section class="benchmark-link">
            <div class="benchmark-link-item">
                <a href="https://github.com/osslab-pku/LiCoEval">
                    <img src="icons/github.svg" alt="GitHub">
                </a>
            </div>
            <div class="benchmark-link-item">
                <a href="https://github.com/osslab-pku/LiCoEval">
                    <img src="icons/huggingface.svg" alt="Hugging Face">
                </a>
            </div>
            <div class="benchmark-link-item">
                <a href="https://arxiv.org/abs/2408.02487">
                    <img src="icons/arxiv.svg" alt="ArXiv">
                </a>
            </div>
        </section>
    </div>
</main>
<div class="graph">
    <canvas id="llmChart"></canvas>
</div>

<div class="leaderboard-table">
    <table>
        <thead>
        <tr>
            <th>Model</th>
            <th>LiCoEval Score</th>
        </tr>
        </thead>
        <tbody>
        <tr>
            <td colspan="2" style="font-weight: bold;">General LLM</td>
        </tr>
        <tr>
            <td>GPT-3.5-Turbo</td>
            <td>0.373</td>
        </tr>
        <tr>
            <td>GPT-4-Turbo</td>
            <td>0.376</td>
        </tr>
        <tr>
            <td>GPT4o</td>
            <td>0.385</td>
        </tr>
        <tr>
            <td>Gemini-1.5-Pro</td>
            <td>0.317</td>
        </tr>
        <tr>
            <td>Claude-3.5-Sonnet</td>
            <td>0.571</td>
        </tr>
        <tr>
            <td>Qwen2-7B-Instruct</td>
            <td>0.985</td>
        </tr>
        <tr>
            <td>GLM-4-9B-Chat</td>
            <td>1.0</td>
        </tr>
        <tr>
            <td>Llama-3-8B-Instruct</td>
            <td>0.714</td>
        </tr>
        <tr>
            <td colspan="2" style="font-weight: bold;">Code LLM</td>
        </tr>
        <tr>
            <td>DeepSeek-Coder-V2</td>
            <td>0.142</td>
        </tr>
        <tr>
            <td>CodeQwen1.5-7B-Chat</td>
            <td>0.781</td>
        </tr>
        <tr>
            <td>StarCoder2-15B-Instruct</td>
            <td>0.780</td>
        </tr>
        <tr>
            <td>Codestral-22B-v0.1</td>
            <td>0.360</td>
        </tr>
        <tr>
            <td>CodeGemma-7B-IT</td>
            <td>0.809</td>
        </tr>
        <tr>
            <td>WizardCoder-Python-13B</td>
            <td>0.153</td>
        </tr>
        </tbody>
    </table>
</div>

<script src="script.js"></script>
</body>
</html>